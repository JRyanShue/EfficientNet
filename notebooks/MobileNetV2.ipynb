{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MobileNetV2.ipynb","provenance":[],"authorship_tag":"ABX9TyOXv6Sttg6v8IvkeE8Vn+pq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"043ff1a0038943428911428a7fef081b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_73f5bcd80bd04ef8baed18e9e7cd1fc6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_59916ed2a77b4e978b3d3af7771bba81","IPY_MODEL_898d0b0faf3a48a2878004a0a34dfbd9","IPY_MODEL_6287ecab4e1043f89bffeead85da84fe"]}},"73f5bcd80bd04ef8baed18e9e7cd1fc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"59916ed2a77b4e978b3d3af7771bba81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_72406b72f31149f1ac7cf2caedce76c6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_639a09fbd5ca4942b85d1b80552d11cb"}},"898d0b0faf3a48a2878004a0a34dfbd9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_172d9b1f5cd740fbb19901ae552ff74d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a1c58f9dd2ca4013816a083c255e8034"}},"6287ecab4e1043f89bffeead85da84fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_db7b3cbd507f4922b2bb7f93dee22e0e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [00:00&lt;00:00,  6.67it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b9879ae218a741ca94456d10a49bd65b"}},"72406b72f31149f1ac7cf2caedce76c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"639a09fbd5ca4942b85d1b80552d11cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"172d9b1f5cd740fbb19901ae552ff74d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a1c58f9dd2ca4013816a083c255e8034":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db7b3cbd507f4922b2bb7f93dee22e0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b9879ae218a741ca94456d10a49bd65b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cwwf7mXR8rI9","executionInfo":{"status":"ok","timestamp":1639283000026,"user_tz":300,"elapsed":8296,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}},"outputId":"8316e1e6-8425-46e7-9ec9-cf3a773f4d93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.16.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.2.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.11.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (5.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.8)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n","Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"]}],"source":["!pip install datasets\n","!pip install tensorflow"]},{"cell_type":"code","source":["\n","from datasets import load_dataset\n","\n","dataset = load_dataset('cifar10')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["043ff1a0038943428911428a7fef081b","73f5bcd80bd04ef8baed18e9e7cd1fc6","59916ed2a77b4e978b3d3af7771bba81","898d0b0faf3a48a2878004a0a34dfbd9","6287ecab4e1043f89bffeead85da84fe","72406b72f31149f1ac7cf2caedce76c6","639a09fbd5ca4942b85d1b80552d11cb","172d9b1f5cd740fbb19901ae552ff74d","a1c58f9dd2ca4013816a083c255e8034","db7b3cbd507f4922b2bb7f93dee22e0e","b9879ae218a741ca94456d10a49bd65b"]},"id":"RDenx4OL9AJ2","executionInfo":{"status":"ok","timestamp":1639283007948,"user_tz":300,"elapsed":7934,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}},"outputId":"55e36aa1-cee3-4ac1-ad2e-d5b368c37385"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Reusing dataset cifar10 (/root/.cache/huggingface/datasets/cifar10/plain_text/1.0.0/5da9550526dac91579c0df95a56466f78e62cc6ea1ccffd17f71f2e64aa86b5e)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"043ff1a0038943428911428a7fef081b","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{}}]},{"cell_type":"code","source":["print(dataset['train'].shape)\n","dataset['test'].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VMa3VqhM9nFA","executionInfo":{"status":"ok","timestamp":1639283007948,"user_tz":300,"elapsed":11,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}},"outputId":"67a8f942-c982-4667-fdee-7d42fa047462"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(50000, 2)\n"]},{"output_type":"execute_result","data":{"text/plain":["(10000, 2)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["dataset['train'].features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0pTiVYew_IqI","executionInfo":{"status":"ok","timestamp":1639283007949,"user_tz":300,"elapsed":9,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}},"outputId":"00d8d6e1-8b3c-49b9-834b-5f3a49980aec"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'img': Array3D(shape=(32, 32, 3), dtype='uint8', id=None),\n"," 'label': ClassLabel(num_classes=10, names=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'], names_file=None, id=None)}"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["dataset['train']['label'][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sNX9X6bt_VTY","executionInfo":{"status":"ok","timestamp":1639283008493,"user_tz":300,"elapsed":551,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}},"outputId":"81f8837f-ab0b-4792-c7a0-889ba8f4ea6a"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"HGHkyjyC_i-G","executionInfo":{"status":"ok","timestamp":1639283013383,"user_tz":300,"elapsed":4894,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Convert dataset into ndarrays\n","\n","(train_x, train_y), (test_x, test_y) = \\\n","  (np.array(dataset['train']['img']), np.array(dataset['train']['label'])), \\\n","  (np.array(dataset['test']['img']), np.array(dataset['test']['label']))\n","\n","# Scale input image pixel values\n","\n","train_x, test_x = train_x / 255.0, test_x / 255.0"],"metadata":{"id":"BE4Rh5-EAf4L","executionInfo":{"status":"ok","timestamp":1639283121218,"user_tz":300,"elapsed":107850,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train_x[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1Y_koAJCqMp","executionInfo":{"status":"ok","timestamp":1639283121219,"user_tz":300,"elapsed":14,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}},"outputId":"4724aa0f-bec7-433e-f55d-33ed9ede7136"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0.69803922, 0.69019608, 0.74117647],\n","        [0.69803922, 0.69019608, 0.74117647],\n","        [0.69803922, 0.69019608, 0.74117647],\n","        ...,\n","        [0.66666667, 0.65882353, 0.70588235],\n","        [0.65882353, 0.65098039, 0.69411765],\n","        [0.64705882, 0.63921569, 0.68235294]],\n","\n","       [[0.70588235, 0.69803922, 0.74901961],\n","        [0.70196078, 0.69411765, 0.74509804],\n","        [0.70588235, 0.69803922, 0.74901961],\n","        ...,\n","        [0.67843137, 0.67058824, 0.71372549],\n","        [0.67058824, 0.6627451 , 0.70588235],\n","        [0.65882353, 0.65098039, 0.69411765]],\n","\n","       [[0.69411765, 0.68627451, 0.7372549 ],\n","        [0.69411765, 0.68627451, 0.7372549 ],\n","        [0.69803922, 0.69019608, 0.74117647],\n","        ...,\n","        [0.67058824, 0.6627451 , 0.70588235],\n","        [0.6627451 , 0.65490196, 0.69803922],\n","        [0.65490196, 0.64705882, 0.69019608]],\n","\n","       ...,\n","\n","       [[0.43921569, 0.41960784, 0.41960784],\n","        [0.44313725, 0.42745098, 0.42352941],\n","        [0.44705882, 0.43137255, 0.43137255],\n","        ...,\n","        [0.39215686, 0.38039216, 0.36862745],\n","        [0.38431373, 0.36862745, 0.36470588],\n","        [0.39607843, 0.37254902, 0.37254902]],\n","\n","       [[0.43921569, 0.4       , 0.39607843],\n","        [0.43921569, 0.40392157, 0.4       ],\n","        [0.44313725, 0.40392157, 0.40392157],\n","        ...,\n","        [0.4       , 0.37254902, 0.36470588],\n","        [0.4       , 0.36470588, 0.35686275],\n","        [0.4       , 0.36078431, 0.35686275]],\n","\n","       [[0.40392157, 0.37647059, 0.36078431],\n","        [0.39215686, 0.36470588, 0.35294118],\n","        [0.40392157, 0.37254902, 0.36862745],\n","        ...,\n","        [0.36078431, 0.32941176, 0.31372549],\n","        [0.36470588, 0.3372549 , 0.31372549],\n","        [0.35686275, 0.32941176, 0.30196078]]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["import os\n","\n","BATCH_SIZE = 96\n","\n","def train_mobilenetv2():\n","\n","  # Define callbacks for early training stopping and model checkpointing\n","\n","  class Callback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","      if logs.get('acc') > 0.3:\n","        print(\"\\nReached stopping point accuracy.\")\n","        self.model.stop_training = True\n","\n","  early_stop_callback = Callback()\n","\n","  checkpoint_path = \"mobileNetV2/model.ckpt\"\n","  checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","  checkpointing_callback = tf.keras.callbacks.ModelCheckpoint(\n","      filepath=checkpoint_path, save_weights_only=True, verbose=1)\n","\n","  # Define MobileNetV2\n","\n","  # Initial 32-output channel convolution\n","  class initial_conv2d(tf.keras.Sequential):\n","    def __init__(self):\n","      tf.keras.Sequential.__init__(self, layers=[\n","        tf.keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same', \n","                               activation=None, name='i_conv'),\n","        tf.keras.layers.BatchNormalization(momentum=0.999, name='i_bnorm'),\n","        tf.keras.layers.ReLU(max_value=6.0, name='i_relu')\n","        ])\n","      \n","  # Final 1280-output channel convolution\n","  class final_conv2d(tf.keras.Sequential):\n","    def __init__(self):\n","      tf.keras.Sequential.__init__(self, layers=[\n","        tf.keras.layers.Conv2D(1280, (1, 1),\n","                               activation=None, name='f_conv'),\n","        tf.keras.layers.BatchNormalization(momentum=0.999, name='f_bnorm'),\n","        tf.keras.layers.ReLU(max_value=6.0, name='f_relu')\n","        ])\n","      \n","  # MBConv inverted residual bottleneck layer\n","  def mbconv2d(input, expansion_factor=1, \n","                 output_channels=16, stride=(1, 1), block_id=1):\n","      \n","      input_channels = input.shape[3]\n","\n","      # Initial 1x1 convolution, multiplying the channel count by the \n","      # expansion factor, widening the representation\n","      conv1 = tf.keras.layers.Conv2D(expansion_factor*input_channels, (1, 1), \n","                              activation=None)(input)\n","      conv1 = tf.keras.layers.BatchNormalization(momentum=0.999)(conv1)\n","      conv1 = tf.keras.layers.ReLU(max_value=6.0)(conv1)\n","      \n","      # Subsequent 3x3 Depthwise convolution, applying an independent kernel\n","      # For each input channel. Stride automatically performs downsampling.\n","      dwconv1 = tf.keras.layers.DepthwiseConv2D((3, 3), stride, padding='same', \n","                              activation='relu6')(conv1)\n","      dwconv1 = tf.keras.layers.BatchNormalization(momentum=0.999)(dwconv1)\n","      dwconv1 = tf.keras.layers.ReLU(max_value=6.0)(dwconv1)\n","      \n","      # Final 1x1 convolution, compressing the channel space into the output\n","      # Channel dimension. No nonlinear activation!\n","      conv2 = tf.keras.layers.Conv2D(output_channels, (1, 1),\n","                              activation=None)(dwconv1)\n","      conv2 = tf.keras.layers.BatchNormalization(momentum=0.999)(conv2)\n","\n","      # Residual connection\n","\n","      # As in ResNet, if the input and output dimensions to not line up, use\n","      # A linear transformation to map the identity into the output space\n","      # if input.shape != conv2.shape:\n","      #   input = tf.keras.layers.Conv2D(conv2.shape[3], (1, 1), \n","      #       activation=None, name='IdentityConv_' + block_id)(input)\n","      #   input = tf.keras.layers.MaxPooling2D(pool_size=(\n","      #       input.shape[1] / conv2.shape[1], input.shape[2] / \n","      #       conv2.shape[2]), name='IdentityMaxpool_' + block_id)(input)\n","      # return tf.keras.layers.Add()([input, conv2])\n","\n","      # Or, just don't do the residual connection if input and output dims don't\n","      # Match up. (This is how the official implementation is done)\n","      if input_channels == output_channels and stride == (1, 1):\n","        return tf.keras.layers.Add(name='Residual_'+block_id)([input, conv2])\n","      else:\n","        return conv2\n","\n","\n","  # Input shape of CIFAR-10 image\n","  inputs = tf.keras.layers.Input(shape=(32, 32, 3))\n","\n","  # Initial 32-output channel convolution\n","  conv1 = initial_conv2d()(inputs)\n","\n","  # First MBConv series: (16, 16, 32) -> (16, 16, 16); t=1, c=16, n=1, s=1\n","  b1a = mbconv2d(conv1, expansion_factor=1, output_channels=16, \n","                   stride=(1, 1), block_id='1a')\n","  \n","  # Second MBConv series: (16, 16, 16) -> (8, 8, 24); t=6, c=24, n=2, s=2\n","  b2a = mbconv2d(b1a, expansion_factor=6, output_channels=24, \n","                   stride=(2, 2), block_id='2a')\n","  b2b = mbconv2d(b2a, expansion_factor=6, output_channels=24, \n","                   stride=(1, 1), block_id='2b')\n","  \n","  # Third MBConv series: (8, 8, 24) -> (4, 4, 32); t=6, c=32, n=3, s=2\n","  b3a = mbconv2d(b2b, expansion_factor=6, output_channels=32, \n","                   stride=(2, 2), block_id='3a')\n","  b3b = mbconv2d(b3a, expansion_factor=6, output_channels=32, \n","                   stride=(1, 1), block_id='3b')\n","  b3c = mbconv2d(b3b, expansion_factor=6, output_channels=32, \n","                   stride=(1, 1), block_id='3c')\n","  \n","  # Fourth MBConv series: (4, 4, 32) -> (2, 2, 64); t=6, c=64, n=4, s=2\n","  b4a = mbconv2d(b3c, expansion_factor=6, output_channels=64, \n","                   stride=(2, 2), block_id='4a')\n","  b4b = mbconv2d(b4a, expansion_factor=6, output_channels=64, \n","                   stride=(1, 1), block_id='4b')\n","  b4c = mbconv2d(b4b, expansion_factor=6, output_channels=64, \n","                   stride=(1, 1), block_id='4c')\n","  b4d = mbconv2d(b4c, expansion_factor=6, output_channels=64, \n","                   stride=(1, 1), block_id='4d')\n","  \n","  # Fifth MBConv series: (2, 2, 64) -> (2, 2, 96); t=6, c=96, n=3, s=1\n","  b5a = mbconv2d(b4d, expansion_factor=6, output_channels=96, \n","                   stride=(1, 1), block_id='5a')\n","  b5b = mbconv2d(b5a, expansion_factor=6, output_channels=96, \n","                   stride=(1, 1), block_id='5b')\n","  b5c = mbconv2d(b5b, expansion_factor=6, output_channels=96, \n","                   stride=(1, 1), block_id='5c')\n","  \n","  # Sixth MBConv series: (2, 2, 96) -> (1, 1, 160); t=6, c=160, n=3, s=2\n","  b6a = mbconv2d(b4d, expansion_factor=6, output_channels=160, \n","                   stride=(1, 1), block_id='6a')\n","  b6b = mbconv2d(b5a, expansion_factor=6, output_channels=160, \n","                   stride=(1, 1), block_id='6b')\n","  b6c = mbconv2d(b5b, expansion_factor=6, output_channels=160, \n","                   stride=(1, 1), block_id='6c')\n","  \n","  # Seventh MBConv series: (1, 1, 160) -> (1, 1, 320); t=6, c=320, n=3, s=1\n","  b7a = mbconv2d(b4d, expansion_factor=6, output_channels=320, \n","                   stride=(1, 1), block_id='7a')\n","  b7b = mbconv2d(b5a, expansion_factor=6, output_channels=320, \n","                   stride=(1, 1), block_id='7b')\n","  b7c = mbconv2d(b5b, expansion_factor=6, output_channels=320, \n","                   stride=(1, 1), block_id='7c')\n","  \n","  # Final convolution\n","  conv2 = final_conv2d()(b7c)\n","\n","  # Dense layer and softmax\n","  flatten = tf.keras.layers.Flatten()(conv2)\n","  d2 = tf.keras.layers.Dense(10, activation=None)(flatten)\n","  d2 = tf.keras.layers.BatchNormalization(momentum=0.999)(d2)\n","  d2 = tf.keras.layers.Softmax()(d2)\n","\n","  model = tf.keras.Model(inputs=inputs, outputs=d2)\n","\n","  schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    0.045, 50000/BATCH_SIZE, 0.98, staircase=False, name='ExpDecaySchedule'\n","  )\n","  optimizer = tf.keras.optimizers.Adam(learning_rate=schedule)\n","  model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', \n","                metrics=['accuracy'])\n","  \n","  model.summary()\n","\n","  history = model.fit(train_x, train_y, epochs=300, callbacks=[\n","    # early_stop_callback, checkpointing_callback])\n","    checkpointing_callback], batch_size=BATCH_SIZE)\n","\n","  # Return metrics\n","  return history.epoch, history.history['accuracy'][-1]\n"],"metadata":{"id":"snYhKu1OATD_","executionInfo":{"status":"ok","timestamp":1639283121220,"user_tz":300,"elapsed":13,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["_, _ = train_mobilenetv2()"],"metadata":{"id":"uqklmge7EvNz","executionInfo":{"status":"error","timestamp":1639288245371,"user_tz":300,"elapsed":5124163,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"26eefec7-02e3-4388-df92-2c1e8b1ad4c2"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n","                                                                                                  \n"," initial_conv2d (initial_conv2d  (None, 16, 16, 32)  1024        ['input_1[0][0]']                \n"," )                                                                                                \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 16, 16, 32)   1056        ['initial_conv2d[0][0]']         \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 16, 16, 32)  128         ['conv2d[0][0]']                 \n"," alization)                                                                                       \n","                                                                                                  \n"," re_lu (ReLU)                   (None, 16, 16, 32)   0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," depthwise_conv2d (DepthwiseCon  (None, 16, 16, 32)  320         ['re_lu[0][0]']                  \n"," v2D)                                                                                             \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 16, 16, 32)  128         ['depthwise_conv2d[0][0]']       \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_1 (ReLU)                 (None, 16, 16, 32)   0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 16, 16, 16)   528         ['re_lu_1[0][0]']                \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 16, 16, 16)  64          ['conv2d_1[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 16, 16, 96)   1632        ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 16, 16, 96)  384         ['conv2d_2[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_2 (ReLU)                 (None, 16, 16, 96)   0           ['batch_normalization_3[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d_1 (DepthwiseC  (None, 8, 8, 96)    960         ['re_lu_2[0][0]']                \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 8, 8, 96)    384         ['depthwise_conv2d_1[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_3 (ReLU)                 (None, 8, 8, 96)     0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 8, 8, 24)     2328        ['re_lu_3[0][0]']                \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 8, 8, 24)    96          ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 8, 8, 144)    3600        ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 8, 8, 144)   576         ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_4 (ReLU)                 (None, 8, 8, 144)    0           ['batch_normalization_6[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d_2 (DepthwiseC  (None, 8, 8, 144)   1440        ['re_lu_4[0][0]']                \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 8, 8, 144)   576         ['depthwise_conv2d_2[0][0]']     \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_5 (ReLU)                 (None, 8, 8, 144)    0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 8, 8, 24)     3480        ['re_lu_5[0][0]']                \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 8, 8, 24)    96          ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," Residual_2b (Add)              (None, 8, 8, 24)     0           ['batch_normalization_5[0][0]',  \n","                                                                  'batch_normalization_8[0][0]']  \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 8, 8, 144)    3600        ['Residual_2b[0][0]']            \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 8, 8, 144)   576         ['conv2d_6[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," re_lu_6 (ReLU)                 (None, 8, 8, 144)    0           ['batch_normalization_9[0][0]']  \n","                                                                                                  \n"," depthwise_conv2d_3 (DepthwiseC  (None, 4, 4, 144)   1440        ['re_lu_6[0][0]']                \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 4, 4, 144)   576         ['depthwise_conv2d_3[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_7 (ReLU)                 (None, 4, 4, 144)    0           ['batch_normalization_10[0][0]'] \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 4, 4, 32)     4640        ['re_lu_7[0][0]']                \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 4, 4, 32)    128         ['conv2d_7[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 4, 4, 192)    6336        ['batch_normalization_11[0][0]'] \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 4, 4, 192)   768         ['conv2d_8[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_8 (ReLU)                 (None, 4, 4, 192)    0           ['batch_normalization_12[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_4 (DepthwiseC  (None, 4, 4, 192)   1920        ['re_lu_8[0][0]']                \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 4, 4, 192)   768         ['depthwise_conv2d_4[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_9 (ReLU)                 (None, 4, 4, 192)    0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 4, 4, 32)     6176        ['re_lu_9[0][0]']                \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 4, 4, 32)    128         ['conv2d_9[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," Residual_3b (Add)              (None, 4, 4, 32)     0           ['batch_normalization_11[0][0]', \n","                                                                  'batch_normalization_14[0][0]'] \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 4, 4, 192)    6336        ['Residual_3b[0][0]']            \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 4, 4, 192)   768         ['conv2d_10[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_10 (ReLU)                (None, 4, 4, 192)    0           ['batch_normalization_15[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_5 (DepthwiseC  (None, 4, 4, 192)   1920        ['re_lu_10[0][0]']               \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 4, 4, 192)   768         ['depthwise_conv2d_5[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_11 (ReLU)                (None, 4, 4, 192)    0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 4, 4, 32)     6176        ['re_lu_11[0][0]']               \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 4, 4, 32)    128         ['conv2d_11[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," Residual_3c (Add)              (None, 4, 4, 32)     0           ['Residual_3b[0][0]',            \n","                                                                  'batch_normalization_17[0][0]'] \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 4, 4, 192)    6336        ['Residual_3c[0][0]']            \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 4, 4, 192)   768         ['conv2d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_12 (ReLU)                (None, 4, 4, 192)    0           ['batch_normalization_18[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_6 (DepthwiseC  (None, 2, 2, 192)   1920        ['re_lu_12[0][0]']               \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 2, 2, 192)   768         ['depthwise_conv2d_6[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_13 (ReLU)                (None, 2, 2, 192)    0           ['batch_normalization_19[0][0]'] \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 2, 2, 64)     12352       ['re_lu_13[0][0]']               \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 2, 2, 64)    256         ['conv2d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 2, 2, 384)    24960       ['batch_normalization_20[0][0]'] \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 2, 2, 384)   1536        ['conv2d_14[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_14 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_21[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_7 (DepthwiseC  (None, 2, 2, 384)   3840        ['re_lu_14[0][0]']               \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 2, 2, 384)   1536        ['depthwise_conv2d_7[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_15 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_22[0][0]'] \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 2, 2, 64)     24640       ['re_lu_15[0][0]']               \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 2, 2, 64)    256         ['conv2d_15[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," Residual_4b (Add)              (None, 2, 2, 64)     0           ['batch_normalization_20[0][0]', \n","                                                                  'batch_normalization_23[0][0]'] \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 2, 2, 384)    24960       ['Residual_4b[0][0]']            \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 2, 2, 384)   1536        ['conv2d_16[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_16 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_24[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_8 (DepthwiseC  (None, 2, 2, 384)   3840        ['re_lu_16[0][0]']               \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 2, 2, 384)   1536        ['depthwise_conv2d_8[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_17 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_25[0][0]'] \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 2, 2, 64)     24640       ['re_lu_17[0][0]']               \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 2, 2, 64)    256         ['conv2d_17[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," Residual_4c (Add)              (None, 2, 2, 64)     0           ['Residual_4b[0][0]',            \n","                                                                  'batch_normalization_26[0][0]'] \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 2, 2, 384)    24960       ['Residual_4c[0][0]']            \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 2, 2, 384)   1536        ['conv2d_18[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_18 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_27[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_9 (DepthwiseC  (None, 2, 2, 384)   3840        ['re_lu_18[0][0]']               \n"," onv2D)                                                                                           \n","                                                                                                  \n"," batch_normalization_28 (BatchN  (None, 2, 2, 384)   1536        ['depthwise_conv2d_9[0][0]']     \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_19 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_28[0][0]'] \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 2, 2, 64)     24640       ['re_lu_19[0][0]']               \n","                                                                                                  \n"," batch_normalization_29 (BatchN  (None, 2, 2, 64)    256         ['conv2d_19[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," Residual_4d (Add)              (None, 2, 2, 64)     0           ['Residual_4c[0][0]',            \n","                                                                  'batch_normalization_29[0][0]'] \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 2, 2, 384)    24960       ['Residual_4d[0][0]']            \n","                                                                                                  \n"," batch_normalization_30 (BatchN  (None, 2, 2, 384)   1536        ['conv2d_20[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_20 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_30[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_10 (Depthwise  (None, 2, 2, 384)   3840        ['re_lu_20[0][0]']               \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_31 (BatchN  (None, 2, 2, 384)   1536        ['depthwise_conv2d_10[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_21 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_31[0][0]'] \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 2, 2, 96)     36960       ['re_lu_21[0][0]']               \n","                                                                                                  \n"," batch_normalization_32 (BatchN  (None, 2, 2, 96)    384         ['conv2d_21[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 2, 2, 576)    55872       ['batch_normalization_32[0][0]'] \n","                                                                                                  \n"," batch_normalization_33 (BatchN  (None, 2, 2, 576)   2304        ['conv2d_22[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_22 (ReLU)                (None, 2, 2, 576)    0           ['batch_normalization_33[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_11 (Depthwise  (None, 2, 2, 576)   5760        ['re_lu_22[0][0]']               \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_34 (BatchN  (None, 2, 2, 576)   2304        ['depthwise_conv2d_11[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_23 (ReLU)                (None, 2, 2, 576)    0           ['batch_normalization_34[0][0]'] \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 2, 2, 96)     55392       ['re_lu_23[0][0]']               \n","                                                                                                  \n"," batch_normalization_35 (BatchN  (None, 2, 2, 96)    384         ['conv2d_23[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," Residual_5b (Add)              (None, 2, 2, 96)     0           ['batch_normalization_32[0][0]', \n","                                                                  'batch_normalization_35[0][0]'] \n","                                                                                                  \n"," conv2d_36 (Conv2D)             (None, 2, 2, 576)    55872       ['Residual_5b[0][0]']            \n","                                                                                                  \n"," batch_normalization_54 (BatchN  (None, 2, 2, 576)   2304        ['conv2d_36[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_36 (ReLU)                (None, 2, 2, 576)    0           ['batch_normalization_54[0][0]'] \n","                                                                                                  \n"," depthwise_conv2d_18 (Depthwise  (None, 2, 2, 576)   5760        ['re_lu_36[0][0]']               \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," batch_normalization_55 (BatchN  (None, 2, 2, 576)   2304        ['depthwise_conv2d_18[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," re_lu_37 (ReLU)                (None, 2, 2, 576)    0           ['batch_normalization_55[0][0]'] \n","                                                                                                  \n"," conv2d_37 (Conv2D)             (None, 2, 2, 320)    184640      ['re_lu_37[0][0]']               \n","                                                                                                  \n"," batch_normalization_56 (BatchN  (None, 2, 2, 320)   1280        ['conv2d_37[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," final_conv2d (final_conv2d)    (None, 2, 2, 1280)   416000      ['batch_normalization_56[0][0]'] \n","                                                                                                  \n"," flatten (Flatten)              (None, 5120)         0           ['final_conv2d[0][0]']           \n","                                                                                                  \n"," dense (Dense)                  (None, 10)           51210       ['flatten[0][0]']                \n","                                                                                                  \n"," batch_normalization_57 (BatchN  (None, 10)          40          ['dense[0][0]']                  \n"," ormalization)                                                                                    \n","                                                                                                  \n"," softmax (Softmax)              (None, 10)           0           ['batch_normalization_57[0][0]'] \n","                                                                                                  \n","==================================================================================================\n","Total params: 1,165,298\n","Trainable params: 1,146,078\n","Non-trainable params: 19,220\n","__________________________________________________________________________________________________\n","Epoch 1/300\n","521/521 [==============================] - ETA: 0s - loss: 1.7450 - accuracy: 0.3411\n","Epoch 00001: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 32s 47ms/step - loss: 1.7450 - accuracy: 0.3411\n","Epoch 2/300\n","521/521 [==============================] - ETA: 0s - loss: 1.3770 - accuracy: 0.5001\n","Epoch 00002: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.3770 - accuracy: 0.5001\n","Epoch 3/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.2308 - accuracy: 0.5578\n","Epoch 00003: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.2308 - accuracy: 0.5578\n","Epoch 4/300\n","521/521 [==============================] - ETA: 0s - loss: 1.1851 - accuracy: 0.5775\n","Epoch 00004: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.1851 - accuracy: 0.5775\n","Epoch 5/300\n","521/521 [==============================] - ETA: 0s - loss: 1.1558 - accuracy: 0.5861\n","Epoch 00005: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.1558 - accuracy: 0.5861\n","Epoch 6/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.1406 - accuracy: 0.5934\n","Epoch 00006: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.1407 - accuracy: 0.5934\n","Epoch 7/300\n","521/521 [==============================] - ETA: 0s - loss: 1.1510 - accuracy: 0.5913\n","Epoch 00007: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.1510 - accuracy: 0.5913\n","Epoch 8/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.1732 - accuracy: 0.5851\n","Epoch 00008: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.1729 - accuracy: 0.5851\n","Epoch 9/300\n","521/521 [==============================] - ETA: 0s - loss: 1.1959 - accuracy: 0.5757\n","Epoch 00009: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.1959 - accuracy: 0.5757\n","Epoch 10/300\n","521/521 [==============================] - ETA: 0s - loss: 1.1982 - accuracy: 0.5749\n","Epoch 00010: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.1982 - accuracy: 0.5749\n","Epoch 11/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.1975 - accuracy: 0.5714\n","Epoch 00011: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.1981 - accuracy: 0.5712\n","Epoch 12/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.1879 - accuracy: 0.5765\n","Epoch 00012: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.1880 - accuracy: 0.5764\n","Epoch 13/300\n","521/521 [==============================] - ETA: 0s - loss: 1.1826 - accuracy: 0.5787\n","Epoch 00013: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.1826 - accuracy: 0.5787\n","Epoch 14/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.1997 - accuracy: 0.5727\n","Epoch 00014: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.1996 - accuracy: 0.5728\n","Epoch 15/300\n","521/521 [==============================] - ETA: 0s - loss: 1.2415 - accuracy: 0.5574\n","Epoch 00015: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.2415 - accuracy: 0.5574\n","Epoch 16/300\n","521/521 [==============================] - ETA: 0s - loss: 1.2055 - accuracy: 0.5683\n","Epoch 00016: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.2055 - accuracy: 0.5683\n","Epoch 17/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.1748 - accuracy: 0.5804\n","Epoch 00017: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.1747 - accuracy: 0.5805\n","Epoch 18/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.1435 - accuracy: 0.5901\n","Epoch 00018: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.1434 - accuracy: 0.5901\n","Epoch 19/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.1177 - accuracy: 0.6017\n","Epoch 00019: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 47ms/step - loss: 1.1177 - accuracy: 0.6016\n","Epoch 20/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.1038 - accuracy: 0.6065\n","Epoch 00020: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.1037 - accuracy: 0.6066\n","Epoch 21/300\n","521/521 [==============================] - ETA: 0s - loss: 1.0839 - accuracy: 0.6139\n","Epoch 00021: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 47ms/step - loss: 1.0839 - accuracy: 0.6139\n","Epoch 22/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.0786 - accuracy: 0.6136\n","Epoch 00022: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 47ms/step - loss: 1.0788 - accuracy: 0.6135\n","Epoch 23/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.0607 - accuracy: 0.6207\n","Epoch 00023: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.0608 - accuracy: 0.6207\n","Epoch 24/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.0457 - accuracy: 0.6285\n","Epoch 00024: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 1.0459 - accuracy: 0.6285\n","Epoch 25/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.0302 - accuracy: 0.6324\n","Epoch 00025: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 47ms/step - loss: 1.0302 - accuracy: 0.6324\n","Epoch 26/300\n","520/521 [============================>.] - ETA: 0s - loss: 1.0320 - accuracy: 0.6305\n","Epoch 00026: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 47ms/step - loss: 1.0321 - accuracy: 0.6305\n","Epoch 27/300\n","521/521 [==============================] - ETA: 0s - loss: 1.0195 - accuracy: 0.6366\n","Epoch 00027: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 47ms/step - loss: 1.0195 - accuracy: 0.6366\n","Epoch 28/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.9966 - accuracy: 0.6449\n","Epoch 00028: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 47ms/step - loss: 0.9963 - accuracy: 0.6450\n","Epoch 29/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.9796 - accuracy: 0.6518\n","Epoch 00029: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 46ms/step - loss: 0.9793 - accuracy: 0.6519\n","Epoch 30/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.9739 - accuracy: 0.6521\n","Epoch 00030: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 24s 47ms/step - loss: 0.9741 - accuracy: 0.6521\n","Epoch 31/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.9550 - accuracy: 0.6588\n","Epoch 00031: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.9550 - accuracy: 0.6590\n","Epoch 32/300\n","521/521 [==============================] - ETA: 0s - loss: 0.9560 - accuracy: 0.6566\n","Epoch 00032: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.9560 - accuracy: 0.6566\n","Epoch 33/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.9438 - accuracy: 0.6631\n","Epoch 00033: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.9440 - accuracy: 0.6629\n","Epoch 34/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.9314 - accuracy: 0.6666\n","Epoch 00034: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.9312 - accuracy: 0.6666\n","Epoch 35/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.9271 - accuracy: 0.6708\n","Epoch 00035: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.9274 - accuracy: 0.6706\n","Epoch 36/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.9152 - accuracy: 0.6741\n","Epoch 00036: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.9151 - accuracy: 0.6741\n","Epoch 37/300\n","521/521 [==============================] - ETA: 0s - loss: 0.9066 - accuracy: 0.6768\n","Epoch 00037: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.9066 - accuracy: 0.6768\n","Epoch 38/300\n","521/521 [==============================] - ETA: 0s - loss: 0.8993 - accuracy: 0.6788\n","Epoch 00038: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.8993 - accuracy: 0.6788\n","Epoch 39/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.8926 - accuracy: 0.6829\n","Epoch 00039: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 47ms/step - loss: 0.8928 - accuracy: 0.6827\n","Epoch 40/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.8819 - accuracy: 0.6848\n","Epoch 00040: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.8818 - accuracy: 0.6849\n","Epoch 41/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.8694 - accuracy: 0.6900\n","Epoch 00041: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.8697 - accuracy: 0.6899\n","Epoch 42/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.8617 - accuracy: 0.6928\n","Epoch 00042: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.8619 - accuracy: 0.6926\n","Epoch 43/300\n","521/521 [==============================] - ETA: 0s - loss: 0.8571 - accuracy: 0.6944\n","Epoch 00043: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.8571 - accuracy: 0.6944\n","Epoch 44/300\n","521/521 [==============================] - ETA: 0s - loss: 0.8504 - accuracy: 0.6968\n","Epoch 00044: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.8504 - accuracy: 0.6968\n","Epoch 45/300\n","521/521 [==============================] - ETA: 0s - loss: 0.8474 - accuracy: 0.6969\n","Epoch 00045: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.8474 - accuracy: 0.6969\n","Epoch 46/300\n","521/521 [==============================] - ETA: 0s - loss: 0.8389 - accuracy: 0.6996\n","Epoch 00046: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 47ms/step - loss: 0.8389 - accuracy: 0.6996\n","Epoch 47/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.8419 - accuracy: 0.7007\n","Epoch 00047: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.8419 - accuracy: 0.7007\n","Epoch 48/300\n","521/521 [==============================] - ETA: 0s - loss: 0.8273 - accuracy: 0.7042\n","Epoch 00048: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.8273 - accuracy: 0.7042\n","Epoch 49/300\n","521/521 [==============================] - ETA: 0s - loss: 0.8176 - accuracy: 0.7082\n","Epoch 00049: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.8176 - accuracy: 0.7082\n","Epoch 50/300\n","521/521 [==============================] - ETA: 0s - loss: 0.8101 - accuracy: 0.7121\n","Epoch 00050: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.8101 - accuracy: 0.7121\n","Epoch 51/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.8066 - accuracy: 0.7102\n","Epoch 00051: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.8067 - accuracy: 0.7101\n","Epoch 52/300\n","521/521 [==============================] - ETA: 0s - loss: 0.7987 - accuracy: 0.7147\n","Epoch 00052: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.7987 - accuracy: 0.7147\n","Epoch 53/300\n","521/521 [==============================] - ETA: 0s - loss: 0.7862 - accuracy: 0.7216\n","Epoch 00053: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.7862 - accuracy: 0.7216\n","Epoch 54/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.7881 - accuracy: 0.7185\n","Epoch 00054: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.7877 - accuracy: 0.7187\n","Epoch 55/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.7793 - accuracy: 0.7229\n","Epoch 00055: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.7791 - accuracy: 0.7231\n","Epoch 56/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.7750 - accuracy: 0.7230\n","Epoch 00056: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.7752 - accuracy: 0.7230\n","Epoch 57/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.7647 - accuracy: 0.7271\n","Epoch 00057: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.7648 - accuracy: 0.7270\n","Epoch 58/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.7576 - accuracy: 0.7294\n","Epoch 00058: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.7577 - accuracy: 0.7294\n","Epoch 59/300\n","521/521 [==============================] - ETA: 0s - loss: 0.7519 - accuracy: 0.7325\n","Epoch 00059: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.7519 - accuracy: 0.7325\n","Epoch 60/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.7443 - accuracy: 0.7337\n","Epoch 00060: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.7441 - accuracy: 0.7337\n","Epoch 61/300\n","521/521 [==============================] - ETA: 0s - loss: 0.7387 - accuracy: 0.7375\n","Epoch 00061: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.7387 - accuracy: 0.7375\n","Epoch 62/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.7305 - accuracy: 0.7377\n","Epoch 00062: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.7305 - accuracy: 0.7377\n","Epoch 63/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.7277 - accuracy: 0.7411\n","Epoch 00063: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.7277 - accuracy: 0.7411\n","Epoch 64/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.7220 - accuracy: 0.7404\n","Epoch 00064: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.7221 - accuracy: 0.7404\n","Epoch 65/300\n","521/521 [==============================] - ETA: 0s - loss: 0.7213 - accuracy: 0.7415\n","Epoch 00065: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.7213 - accuracy: 0.7415\n","Epoch 66/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.7082 - accuracy: 0.7469\n","Epoch 00066: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.7081 - accuracy: 0.7469\n","Epoch 67/300\n","521/521 [==============================] - ETA: 0s - loss: 0.7036 - accuracy: 0.7476\n","Epoch 00067: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.7036 - accuracy: 0.7476\n","Epoch 68/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.6953 - accuracy: 0.7511\n","Epoch 00068: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.6952 - accuracy: 0.7511\n","Epoch 69/300\n","521/521 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.7516\n","Epoch 00069: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.6926 - accuracy: 0.7516\n","Epoch 70/300\n","521/521 [==============================] - ETA: 0s - loss: 0.6850 - accuracy: 0.7537\n","Epoch 00070: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.6850 - accuracy: 0.7537\n","Epoch 71/300\n","521/521 [==============================] - ETA: 0s - loss: 0.6831 - accuracy: 0.7556\n","Epoch 00071: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.6831 - accuracy: 0.7556\n","Epoch 72/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.6722 - accuracy: 0.7595\n","Epoch 00072: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.6721 - accuracy: 0.7596\n","Epoch 73/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.6701 - accuracy: 0.7596\n","Epoch 00073: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.6702 - accuracy: 0.7595\n","Epoch 74/300\n","521/521 [==============================] - ETA: 0s - loss: 0.6671 - accuracy: 0.7617\n","Epoch 00074: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.6671 - accuracy: 0.7617\n","Epoch 75/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.6589 - accuracy: 0.7642\n","Epoch 00075: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.6588 - accuracy: 0.7642\n","Epoch 76/300\n","521/521 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.7665\n","Epoch 00076: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.6512 - accuracy: 0.7665\n","Epoch 77/300\n","521/521 [==============================] - ETA: 0s - loss: 0.6492 - accuracy: 0.7678\n","Epoch 00077: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.6492 - accuracy: 0.7678\n","Epoch 78/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.6398 - accuracy: 0.7710\n","Epoch 00078: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.6399 - accuracy: 0.7709\n","Epoch 79/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.6326 - accuracy: 0.7754\n","Epoch 00079: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.6327 - accuracy: 0.7754\n","Epoch 80/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.6310 - accuracy: 0.7733\n","Epoch 00080: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.6308 - accuracy: 0.7734\n","Epoch 81/300\n","521/521 [==============================] - ETA: 0s - loss: 0.6204 - accuracy: 0.7769\n","Epoch 00081: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.6204 - accuracy: 0.7769\n","Epoch 82/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.6183 - accuracy: 0.7780\n","Epoch 00082: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.6180 - accuracy: 0.7781\n","Epoch 83/300\n","521/521 [==============================] - ETA: 0s - loss: 0.6124 - accuracy: 0.7812\n","Epoch 00083: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.6124 - accuracy: 0.7812\n","Epoch 84/300\n","521/521 [==============================] - ETA: 0s - loss: 0.6081 - accuracy: 0.7826\n","Epoch 00084: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.6081 - accuracy: 0.7826\n","Epoch 85/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.6019 - accuracy: 0.7840\n","Epoch 00085: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.6019 - accuracy: 0.7840\n","Epoch 86/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.5948 - accuracy: 0.7858\n","Epoch 00086: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.5946 - accuracy: 0.7859\n","Epoch 87/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.5968 - accuracy: 0.7865\n","Epoch 00087: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.5968 - accuracy: 0.7864\n","Epoch 88/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.5834 - accuracy: 0.7901\n","Epoch 00088: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.5832 - accuracy: 0.7901\n","Epoch 89/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.5816 - accuracy: 0.7924\n","Epoch 00089: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.5814 - accuracy: 0.7924\n","Epoch 90/300\n","521/521 [==============================] - ETA: 0s - loss: 0.5731 - accuracy: 0.7931\n","Epoch 00090: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.5731 - accuracy: 0.7931\n","Epoch 91/300\n","521/521 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.7980\n","Epoch 00091: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.5620 - accuracy: 0.7980\n","Epoch 92/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.5662 - accuracy: 0.7964\n","Epoch 00092: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.5663 - accuracy: 0.7964\n","Epoch 93/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.5586 - accuracy: 0.7984\n","Epoch 00093: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.5586 - accuracy: 0.7983\n","Epoch 94/300\n","521/521 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.8018\n","Epoch 00094: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.5550 - accuracy: 0.8018\n","Epoch 95/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.5495 - accuracy: 0.8019\n","Epoch 00095: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.5495 - accuracy: 0.8019\n","Epoch 96/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.5448 - accuracy: 0.8035\n","Epoch 00096: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.5448 - accuracy: 0.8035\n","Epoch 97/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.5353 - accuracy: 0.8083\n","Epoch 00097: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.5356 - accuracy: 0.8082\n","Epoch 98/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.5289 - accuracy: 0.8112\n","Epoch 00098: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.5290 - accuracy: 0.8112\n","Epoch 99/300\n","521/521 [==============================] - ETA: 0s - loss: 0.5274 - accuracy: 0.8105\n","Epoch 00099: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.5274 - accuracy: 0.8105\n","Epoch 100/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.5157 - accuracy: 0.8129\n","Epoch 00100: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.5157 - accuracy: 0.8128\n","Epoch 101/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.5113 - accuracy: 0.8155\n","Epoch 00101: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.5114 - accuracy: 0.8155\n","Epoch 102/300\n","521/521 [==============================] - ETA: 0s - loss: 0.5155 - accuracy: 0.8165\n","Epoch 00102: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.5155 - accuracy: 0.8165\n","Epoch 103/300\n","521/521 [==============================] - ETA: 0s - loss: 0.5059 - accuracy: 0.8181\n","Epoch 00103: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.5059 - accuracy: 0.8181\n","Epoch 104/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.5026 - accuracy: 0.8184\n","Epoch 00104: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.5026 - accuracy: 0.8184\n","Epoch 105/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4975 - accuracy: 0.8209\n","Epoch 00105: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.4972 - accuracy: 0.8210\n","Epoch 106/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4885 - accuracy: 0.8234\n","Epoch 00106: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.4889 - accuracy: 0.8233\n","Epoch 107/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4845 - accuracy: 0.8247\n","Epoch 00107: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.4847 - accuracy: 0.8247\n","Epoch 108/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4777 - accuracy: 0.8275\n","Epoch 00108: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.4777 - accuracy: 0.8275\n","Epoch 109/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4762 - accuracy: 0.8274\n","Epoch 00109: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.4761 - accuracy: 0.8274\n","Epoch 110/300\n","521/521 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.8292\n","Epoch 00110: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.4744 - accuracy: 0.8292\n","Epoch 111/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4717 - accuracy: 0.8317\n","Epoch 00111: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.4718 - accuracy: 0.8316\n","Epoch 112/300\n","521/521 [==============================] - ETA: 0s - loss: 0.4599 - accuracy: 0.8346\n","Epoch 00112: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.4599 - accuracy: 0.8346\n","Epoch 113/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4551 - accuracy: 0.8364\n","Epoch 00113: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.4551 - accuracy: 0.8364\n","Epoch 114/300\n","521/521 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.8365\n","Epoch 00114: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.4546 - accuracy: 0.8365\n","Epoch 115/300\n","521/521 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.8376\n","Epoch 00115: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.4505 - accuracy: 0.8376\n","Epoch 116/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4474 - accuracy: 0.8370\n","Epoch 00116: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.4472 - accuracy: 0.8370\n","Epoch 117/300\n","521/521 [==============================] - ETA: 0s - loss: 0.4412 - accuracy: 0.8428\n","Epoch 00117: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.4412 - accuracy: 0.8428\n","Epoch 118/300\n","521/521 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.8409\n","Epoch 00118: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.4373 - accuracy: 0.8409\n","Epoch 119/300\n","521/521 [==============================] - ETA: 0s - loss: 0.4323 - accuracy: 0.8438\n","Epoch 00119: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.4323 - accuracy: 0.8438\n","Epoch 120/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4280 - accuracy: 0.8456\n","Epoch 00120: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.4282 - accuracy: 0.8456\n","Epoch 121/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4276 - accuracy: 0.8455\n","Epoch 00121: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.4275 - accuracy: 0.8455\n","Epoch 122/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4178 - accuracy: 0.8493\n","Epoch 00122: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.4179 - accuracy: 0.8493\n","Epoch 123/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4171 - accuracy: 0.8481\n","Epoch 00123: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.4170 - accuracy: 0.8482\n","Epoch 124/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4170 - accuracy: 0.8499\n","Epoch 00124: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.4170 - accuracy: 0.8499\n","Epoch 125/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4089 - accuracy: 0.8513\n","Epoch 00125: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.4088 - accuracy: 0.8514\n","Epoch 126/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3998 - accuracy: 0.8551\n","Epoch 00126: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.3997 - accuracy: 0.8552\n","Epoch 127/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.4058 - accuracy: 0.8531\n","Epoch 00127: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.4059 - accuracy: 0.8531\n","Epoch 128/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3984 - accuracy: 0.8552\n","Epoch 00128: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3984 - accuracy: 0.8552\n","Epoch 129/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3976 - accuracy: 0.8558\n","Epoch 00129: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3976 - accuracy: 0.8558\n","Epoch 130/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3922 - accuracy: 0.8581\n","Epoch 00130: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3922 - accuracy: 0.8581\n","Epoch 131/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.8601\n","Epoch 00131: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3871 - accuracy: 0.8601\n","Epoch 132/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.8596\n","Epoch 00132: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.3900 - accuracy: 0.8596\n","Epoch 133/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8610\n","Epoch 00133: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.3852 - accuracy: 0.8610\n","Epoch 134/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3762 - accuracy: 0.8636\n","Epoch 00134: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.3764 - accuracy: 0.8634\n","Epoch 135/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3746 - accuracy: 0.8636\n","Epoch 00135: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.3745 - accuracy: 0.8636\n","Epoch 136/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3714 - accuracy: 0.8637\n","Epoch 00136: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.3714 - accuracy: 0.8637\n","Epoch 137/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3712 - accuracy: 0.8666\n","Epoch 00137: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3712 - accuracy: 0.8666\n","Epoch 138/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3708 - accuracy: 0.8643\n","Epoch 00138: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 48ms/step - loss: 0.3708 - accuracy: 0.8643\n","Epoch 139/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3654 - accuracy: 0.8679\n","Epoch 00139: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3653 - accuracy: 0.8679\n","Epoch 140/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3569 - accuracy: 0.8707\n","Epoch 00140: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3568 - accuracy: 0.8707\n","Epoch 141/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3572 - accuracy: 0.8708\n","Epoch 00141: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3570 - accuracy: 0.8708\n","Epoch 142/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3543 - accuracy: 0.8714\n","Epoch 00142: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3544 - accuracy: 0.8713\n","Epoch 143/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3518 - accuracy: 0.8727\n","Epoch 00143: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.3518 - accuracy: 0.8727\n","Epoch 144/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3474 - accuracy: 0.8738\n","Epoch 00144: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3476 - accuracy: 0.8738\n","Epoch 145/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.8736\n","Epoch 00145: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3465 - accuracy: 0.8736\n","Epoch 146/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3426 - accuracy: 0.8757\n","Epoch 00146: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 25s 49ms/step - loss: 0.3426 - accuracy: 0.8757\n","Epoch 147/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.8762\n","Epoch 00147: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3406 - accuracy: 0.8762\n","Epoch 148/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3367 - accuracy: 0.8767\n","Epoch 00148: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3367 - accuracy: 0.8767\n","Epoch 149/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3371 - accuracy: 0.8786\n","Epoch 00149: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 27s 51ms/step - loss: 0.3370 - accuracy: 0.8786\n","Epoch 150/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3319 - accuracy: 0.8798\n","Epoch 00150: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3319 - accuracy: 0.8798\n","Epoch 151/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3333 - accuracy: 0.8786\n","Epoch 00151: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3332 - accuracy: 0.8787\n","Epoch 152/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3278 - accuracy: 0.8806\n","Epoch 00152: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3279 - accuracy: 0.8805\n","Epoch 153/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3282 - accuracy: 0.8820\n","Epoch 00153: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3282 - accuracy: 0.8820\n","Epoch 154/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3226 - accuracy: 0.8827\n","Epoch 00154: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3226 - accuracy: 0.8827\n","Epoch 155/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.8835\n","Epoch 00155: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.3218 - accuracy: 0.8835\n","Epoch 156/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3165 - accuracy: 0.8863\n","Epoch 00156: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3166 - accuracy: 0.8862\n","Epoch 157/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3196 - accuracy: 0.8831\n","Epoch 00157: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 49ms/step - loss: 0.3197 - accuracy: 0.8830\n","Epoch 158/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3179 - accuracy: 0.8848\n","Epoch 00158: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.3177 - accuracy: 0.8849\n","Epoch 159/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3087 - accuracy: 0.8872\n","Epoch 00159: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.3086 - accuracy: 0.8872\n","Epoch 160/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3142 - accuracy: 0.8859\n","Epoch 00160: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.3143 - accuracy: 0.8858\n","Epoch 161/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3109 - accuracy: 0.8868\n","Epoch 00161: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.3109 - accuracy: 0.8868\n","Epoch 162/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3067 - accuracy: 0.8863\n","Epoch 00162: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.3066 - accuracy: 0.8863\n","Epoch 163/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3075 - accuracy: 0.8877\n","Epoch 00163: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.3075 - accuracy: 0.8877\n","Epoch 164/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.3036 - accuracy: 0.8890\n","Epoch 00164: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.3036 - accuracy: 0.8890\n","Epoch 165/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3044 - accuracy: 0.8892\n","Epoch 00165: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 27s 51ms/step - loss: 0.3044 - accuracy: 0.8892\n","Epoch 166/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2987 - accuracy: 0.8909\n","Epoch 00166: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.2987 - accuracy: 0.8909\n","Epoch 167/300\n","521/521 [==============================] - ETA: 0s - loss: 0.3027 - accuracy: 0.8897\n","Epoch 00167: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.3027 - accuracy: 0.8897\n","Epoch 168/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2997 - accuracy: 0.8899\n","Epoch 00168: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.2997 - accuracy: 0.8899\n","Epoch 169/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2962 - accuracy: 0.8919\n","Epoch 00169: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.2961 - accuracy: 0.8919\n","Epoch 170/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2876 - accuracy: 0.8956\n","Epoch 00170: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.2876 - accuracy: 0.8956\n","Epoch 171/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2903 - accuracy: 0.8932\n","Epoch 00171: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.2902 - accuracy: 0.8933\n","Epoch 172/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.8938\n","Epoch 00172: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.2925 - accuracy: 0.8938\n","Epoch 173/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2870 - accuracy: 0.8964\n","Epoch 00173: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.2870 - accuracy: 0.8963\n","Epoch 174/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.8966\n","Epoch 00174: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.2878 - accuracy: 0.8966\n","Epoch 175/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2838 - accuracy: 0.8971\n","Epoch 00175: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.2839 - accuracy: 0.8970\n","Epoch 176/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2824 - accuracy: 0.8978\n","Epoch 00176: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.2824 - accuracy: 0.8978\n","Epoch 177/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2874 - accuracy: 0.8956\n","Epoch 00177: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.2875 - accuracy: 0.8956\n","Epoch 178/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2834 - accuracy: 0.8972\n","Epoch 00178: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.2834 - accuracy: 0.8972\n","Epoch 179/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.8982\n","Epoch 00179: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.2772 - accuracy: 0.8982\n","Epoch 180/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2826 - accuracy: 0.8981\n","Epoch 00180: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.2826 - accuracy: 0.8981\n","Epoch 181/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2766 - accuracy: 0.8989\n","Epoch 00181: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.2766 - accuracy: 0.8989\n","Epoch 182/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2724 - accuracy: 0.9015\n","Epoch 00182: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 50ms/step - loss: 0.2724 - accuracy: 0.9015\n","Epoch 183/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2699 - accuracy: 0.9020\n","Epoch 00183: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.2699 - accuracy: 0.9020\n","Epoch 184/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2742 - accuracy: 0.9010\n","Epoch 00184: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 27s 51ms/step - loss: 0.2742 - accuracy: 0.9010\n","Epoch 185/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2775 - accuracy: 0.8998\n","Epoch 00185: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 27s 51ms/step - loss: 0.2775 - accuracy: 0.8998\n","Epoch 186/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.9036\n","Epoch 00186: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 27s 51ms/step - loss: 0.2674 - accuracy: 0.9036\n","Epoch 187/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2734 - accuracy: 0.9004\n","Epoch 00187: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 27s 51ms/step - loss: 0.2735 - accuracy: 0.9003\n","Epoch 188/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2690 - accuracy: 0.9023\n","Epoch 00188: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 27s 51ms/step - loss: 0.2691 - accuracy: 0.9022\n","Epoch 189/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.9001\n","Epoch 00189: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.2721 - accuracy: 0.9001\n","Epoch 190/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2706 - accuracy: 0.9026\n","Epoch 00190: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 27s 52ms/step - loss: 0.2707 - accuracy: 0.9026\n","Epoch 191/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.9052\n","Epoch 00191: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.2632 - accuracy: 0.9052\n","Epoch 192/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.9040\n","Epoch 00192: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.2623 - accuracy: 0.9040\n","Epoch 193/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.9048\n","Epoch 00193: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 27s 51ms/step - loss: 0.2619 - accuracy: 0.9048\n","Epoch 194/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2634 - accuracy: 0.9045\n","Epoch 00194: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.2633 - accuracy: 0.9045\n","Epoch 195/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2624 - accuracy: 0.9055\n","Epoch 00195: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 27s 51ms/step - loss: 0.2630 - accuracy: 0.9053\n","Epoch 196/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2605 - accuracy: 0.9034\n","Epoch 00196: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 27s 52ms/step - loss: 0.2605 - accuracy: 0.9034\n","Epoch 197/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2602 - accuracy: 0.9062\n","Epoch 00197: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 27s 51ms/step - loss: 0.2603 - accuracy: 0.9062\n","Epoch 198/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2615 - accuracy: 0.9048\n","Epoch 00198: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.2615 - accuracy: 0.9048\n","Epoch 199/300\n","520/521 [============================>.] - ETA: 0s - loss: 0.2615 - accuracy: 0.9057\n","Epoch 00199: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 27s 51ms/step - loss: 0.2615 - accuracy: 0.9057\n","Epoch 200/300\n","521/521 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 0.9095\n","Epoch 00200: saving model to mobileNetV2/model.ckpt\n","521/521 [==============================] - 26s 51ms/step - loss: 0.2521 - accuracy: 0.9095\n","Epoch 201/300\n","112/521 [=====>........................] - ETA: 20s - loss: 0.2548 - accuracy: 0.9066"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-8a0311174a1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mobilenetv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-f79ef4adf7f4>\u001b[0m in \u001b[0;36mtrain_mobilenetv2\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m   history = model.fit(train_x, train_y, epochs=300, callbacks=[\n\u001b[1;32m    170\u001b[0m     \u001b[0;31m# early_stop_callback, checkpointing_callback])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     checkpointing_callback], batch_size=BATCH_SIZE)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m   \u001b[0;31m# Return metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["!pip install matplotlib"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-FP-x0OnJfmb","executionInfo":{"status":"ok","timestamp":1639254089252,"user_tz":300,"elapsed":3356,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}},"outputId":"3bb2a0d3-de11-4421-87c4-b6c60e01c862"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.imshow(test_x[2])\n","test_y[2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"DrzWgjtjJy4g","executionInfo":{"status":"ok","timestamp":1639254400528,"user_tz":300,"elapsed":369,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}},"outputId":"c877a12b-4878-439a-91bb-e59cbcb9b010"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":53},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["!zip -r /content/mobileNetV2.zip /content/mobileNetV2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FSx1wmbGLiwV","executionInfo":{"status":"ok","timestamp":1639288267235,"user_tz":300,"elapsed":995,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}},"outputId":"e20c670e-23d7-475a-9dfd-3ed267321d85"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/mobileNetV2/ (stored 0%)\n","  adding: content/mobileNetV2/model.ckpt.index (deflated 80%)\n","  adding: content/mobileNetV2/model.ckpt.data-00000-of-00001 (deflated 39%)\n","  adding: content/mobileNetV2/checkpoint (deflated 42%)\n"]}]},{"cell_type":"code","source":["# Initial 32-output channel convolution\n","class initial_conv2d(tf.keras.Sequential):\n","  def __init__(self):\n","    tf.keras.Sequential.__init__(self, layers=[\n","      tf.keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same', \n","                              activation=None, name='i_conv'),\n","      tf.keras.layers.BatchNormalization(momentum=0.999, name='i_bnorm'),\n","      tf.keras.layers.ReLU(max_value=6.0, name='i_relu')\n","      ])\n","    \n","# Final 1280-output channel convolution\n","class final_conv2d(tf.keras.Sequential):\n","  def __init__(self):\n","    tf.keras.Sequential.__init__(self, layers=[\n","      tf.keras.layers.Conv2D(1280, (1, 1),\n","                              activation=None, name='f_conv'),\n","      tf.keras.layers.BatchNormalization(momentum=0.999, name='f_bnorm'),\n","      tf.keras.layers.ReLU(max_value=6.0, name='f_relu')\n","      ])\n","    \n","# MBConv inverted residual bottleneck layer\n","def mbconv2d(input, expansion_factor=1, \n","                output_channels=16, stride=(1, 1), block_id=1):\n","    \n","    input_channels = input.shape[3]\n","\n","    # Initial 1x1 convolution, multiplying the channel count by the \n","    # expansion factor, widening the representation\n","    conv1 = tf.keras.layers.Conv2D(expansion_factor*input_channels, (1, 1), \n","                            activation=None)(input)\n","    conv1 = tf.keras.layers.BatchNormalization(momentum=0.999)(conv1)\n","    conv1 = tf.keras.layers.ReLU(max_value=6.0)(conv1)\n","    \n","    # Subsequent 3x3 Depthwise convolution, applying an independent kernel\n","    # For each input channel. Stride automatically performs downsampling.\n","    dwconv1 = tf.keras.layers.DepthwiseConv2D((3, 3), stride, padding='same', \n","                            activation='relu6')(conv1)\n","    dwconv1 = tf.keras.layers.BatchNormalization(momentum=0.999)(dwconv1)\n","    dwconv1 = tf.keras.layers.ReLU(max_value=6.0)(dwconv1)\n","    \n","    # Final 1x1 convolution, compressing the channel space into the output\n","    # Channel dimension. No nonlinear activation!\n","    conv2 = tf.keras.layers.Conv2D(output_channels, (1, 1),\n","                            activation=None)(dwconv1)\n","    conv2 = tf.keras.layers.BatchNormalization(momentum=0.999)(conv2)\n","\n","    # Residual connection\n","\n","    # As in ResNet, if the input and output dimensions to not line up, use\n","    # A linear transformation to map the identity into the output space\n","    # if input.shape != conv2.shape:\n","    #   input = tf.keras.layers.Conv2D(conv2.shape[3], (1, 1), \n","    #       activation=None, name='IdentityConv_' + block_id)(input)\n","    #   input = tf.keras.layers.MaxPooling2D(pool_size=(\n","    #       input.shape[1] / conv2.shape[1], input.shape[2] / \n","    #       conv2.shape[2]), name='IdentityMaxpool_' + block_id)(input)\n","    # return tf.keras.layers.Add()([input, conv2])\n","\n","    # Or, just don't do the residual connection if input and output dims don't\n","    # Match up. (This is how the official implementation is done)\n","    if input_channels == output_channels and stride == (1, 1):\n","      return tf.keras.layers.Add(name='Residual_'+block_id)([input, conv2])\n","    else:\n","      return conv2\n","\n","\n","# Input shape of CIFAR-10 image\n","inputs = tf.keras.layers.Input(shape=(32, 32, 3))\n","\n","# Initial 32-output channel convolution\n","conv1 = initial_conv2d()(inputs)\n","\n","# First MBConv series: (16, 16, 32) -> (16, 16, 16); t=1, c=16, n=1, s=1\n","b1a = mbconv2d(conv1, expansion_factor=1, output_channels=16, \n","                  stride=(1, 1), block_id='1a')\n","\n","# Second MBConv series: (16, 16, 16) -> (8, 8, 24); t=6, c=24, n=2, s=2\n","b2a = mbconv2d(b1a, expansion_factor=6, output_channels=24, \n","                  stride=(2, 2), block_id='2a')\n","b2b = mbconv2d(b2a, expansion_factor=6, output_channels=24, \n","                  stride=(1, 1), block_id='2b')\n","\n","# Third MBConv series: (8, 8, 24) -> (4, 4, 32); t=6, c=32, n=3, s=2\n","b3a = mbconv2d(b2b, expansion_factor=6, output_channels=32, \n","                  stride=(2, 2), block_id='3a')\n","b3b = mbconv2d(b3a, expansion_factor=6, output_channels=32, \n","                  stride=(1, 1), block_id='3b')\n","b3c = mbconv2d(b3b, expansion_factor=6, output_channels=32, \n","                  stride=(1, 1), block_id='3c')\n","\n","# Fourth MBConv series: (4, 4, 32) -> (2, 2, 64); t=6, c=64, n=4, s=2\n","b4a = mbconv2d(b3c, expansion_factor=6, output_channels=64, \n","                  stride=(2, 2), block_id='4a')\n","b4b = mbconv2d(b4a, expansion_factor=6, output_channels=64, \n","                  stride=(1, 1), block_id='4b')\n","b4c = mbconv2d(b4b, expansion_factor=6, output_channels=64, \n","                  stride=(1, 1), block_id='4c')\n","b4d = mbconv2d(b4c, expansion_factor=6, output_channels=64, \n","                  stride=(1, 1), block_id='4d')\n","\n","# Fifth MBConv series: (2, 2, 64) -> (2, 2, 96); t=6, c=96, n=3, s=1\n","b5a = mbconv2d(b4d, expansion_factor=6, output_channels=96, \n","                  stride=(1, 1), block_id='5a')\n","b5b = mbconv2d(b5a, expansion_factor=6, output_channels=96, \n","                  stride=(1, 1), block_id='5b')\n","b5c = mbconv2d(b5b, expansion_factor=6, output_channels=96, \n","                  stride=(1, 1), block_id='5c')\n","\n","# Sixth MBConv series: (2, 2, 96) -> (1, 1, 160); t=6, c=160, n=3, s=2\n","b6a = mbconv2d(b4d, expansion_factor=6, output_channels=160, \n","                  stride=(1, 1), block_id='6a')\n","b6b = mbconv2d(b5a, expansion_factor=6, output_channels=160, \n","                  stride=(1, 1), block_id='6b')\n","b6c = mbconv2d(b5b, expansion_factor=6, output_channels=160, \n","                  stride=(1, 1), block_id='6c')\n","\n","# Seventh MBConv series: (1, 1, 160) -> (1, 1, 320); t=6, c=320, n=3, s=1\n","b7a = mbconv2d(b4d, expansion_factor=6, output_channels=320, \n","                  stride=(1, 1), block_id='7a')\n","b7b = mbconv2d(b5a, expansion_factor=6, output_channels=320, \n","                  stride=(1, 1), block_id='7b')\n","b7c = mbconv2d(b5b, expansion_factor=6, output_channels=320, \n","                  stride=(1, 1), block_id='7c')\n","\n","# Final convolution\n","conv2 = final_conv2d()(b7c)\n","\n","# Dense layer and softmax\n","flatten = tf.keras.layers.Flatten()(conv2)\n","d2 = tf.keras.layers.Dense(10, activation=None)(flatten)\n","d2 = tf.keras.layers.BatchNormalization(momentum=0.999)(d2)\n","d2 = tf.keras.layers.Softmax()(d2)\n","\n","model = tf.keras.Model(inputs=inputs, outputs=d2)\n","\n","schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","  0.045, 50000/BATCH_SIZE, 0.98, staircase=False, name='ExpDecaySchedule'\n",")\n","optimizer = tf.keras.optimizers.Adam(learning_rate=schedule)\n","model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', \n","              metrics=['accuracy'])\n","  \n","model.load_weights('mobileNetV2/model.ckpt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYRs1zH7MCh0","executionInfo":{"status":"ok","timestamp":1639288484616,"user_tz":300,"elapsed":3447,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}},"outputId":"6433f9ef-234d-4cd3-d89b-0cd3a88994fc"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f851fcf3210>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["model.evaluate(test_x, test_y, verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mz6iI0aPMam9","executionInfo":{"status":"ok","timestamp":1639288495557,"user_tz":300,"elapsed":6897,"user":{"displayName":"Ryan Shue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg65rZPkz5bJ7ik0h6ITKz45vgUzj81potiaE77Dw=s64","userId":"11228421312565688614"}},"outputId":"48fdb388-8748-40eb-e61e-fbcc6836a628"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 - 5s - loss: 1.4163 - accuracy: 0.6778 - 5s/epoch - 17ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.4163216352462769, 0.6777999997138977]"]},"metadata":{},"execution_count":17}]}]}